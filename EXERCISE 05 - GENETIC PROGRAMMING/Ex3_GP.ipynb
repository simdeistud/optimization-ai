{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Regression on Feynman Equations using Genetic Programming\n",
    "\n",
    "Symbolic regression is a type of regression analysis where the goal is to discover mathematical expressions that best describe a given dataset. Unlike traditional regression, symbolic regression does not assume a predefined model structure. Instead, it searches for both the structure and the parameters that best fit the data. This approach can yield interpretable, analytical models that help uncover underlying relationships in the data.\n",
    "\n",
    "In this notebook, we will apply symbolic regression to a set of well-known physical equations: the Feynman Equations. These equations, derived by physicist Richard Feynman, describe fundamental physical phenomena in areas such as mechanics, electromagnetism, and thermodynamics.\n",
    "\n",
    "We will perform symbolic regression with **genetic programming** (GP), using `gplearn`, a `scikit-learn`-inspired Python library for GP.\n",
    "\n",
    "Let us import some useful modules. \n",
    "If you are using `conda`, you can install `graphviz` with the following commands:\n",
    "\n",
    "```\n",
    "conda install graphviz\n",
    "conda install python-graphviz\n",
    "conda install pydot\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Penn Machine Learning Benchmarks\n",
    "%pip install -U git+https://github.com/EpistasisLab/pmlb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import clear_output\n",
    "from pmlb import fetch_data\n",
    "import gplearn.genetic as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the eqations from the csv file and fetch the correcponding data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "eq_df = pd.read_csv('../data/FeynmanEquations.csv')\n",
    "eq_df.dropna(axis = 0, how = 'all', inplace = True)\n",
    "eq_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "eq_df.Filename = eq_df.Filename.apply(lambda x: 'feynman_' + x.replace('.', '_'))\n",
    "eq_df = eq_df.loc[:, ['Filename', 'Formula']]\n",
    "\n",
    "#feynman_I_15_10 in pmlb equal to I.15.1 in original source\n",
    "eq_df.Filename = eq_df.Filename.apply(lambda x: x.replace('feynman_I_15_1', 'feynman_I_15_10'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a subset of equations (we don't have enough time to test them all)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset_names = eq_df[\"Filename\"].to_list()\n",
    "datasets_to_test_names = dataset_names[3:8]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "datasets={}\n",
    "for name in datasets_to_test_names:\n",
    "    datasets[name] = fetch_data(name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each equation in the dataset, perform symbolic regression using GP. Split each dataset into a training set and a validation set. Select a validation metric to evaluate performance, noting that this metric is not necessarily the same as the GP fitness function. Experiment with different sets of hyperparameters to observe how the results change.\n",
    "\n",
    "Take a look at the [documentation](https://gplearn.readthedocs.io/en/stable/intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from gplearn.genetic import BaseSymbolic\n",
    "from sklearn.utils.validation import validate_data\n",
    "\n",
    "BaseSymbolic._validate_data = lambda self, *args, **kwargs: validate_data(\n",
    "    self,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "random_state = 0\n",
    "\n",
    "#hyperparameters\n",
    "max_gen = \n",
    "fset = () # Hint: you can also define your own!\n",
    "pop_size = \n",
    "tournament_size = \n",
    "parsimony_coefficient = \n",
    "p_crossover =\n",
    "p_subtree_mutation = \n",
    "p_hoist_mutation=\n",
    "p_point_mutation=\n",
    "fitness =\n",
    "val_fit = \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(random_state)\n",
    "results = pd.DataFrame(columns=['dataset','best_fit', 'original', 'equation'])\n",
    "loss_histories = {}\n",
    "\n",
    "cnt = 0\n",
    "for name, df in datasets.items():\n",
    "    cnt = cnt + 1\n",
    "    # CODE HERE\n",
    "    \n",
    "    loss_history = []\n",
    "    var_names = df.drop(columns=['target']).columns.tolist()\n",
    "    \n",
    "    sr = gp.SymbolicRegressor(population_size=pop_size,\n",
    "                                tournament_size=tournament_size,\n",
    "                                function_set=fset,\n",
    "                                parsimony_coefficient=parsimony_coefficient,\n",
    "                                p_crossover=p_crossover,\n",
    "                                p_subtree_mutation=p_subtree_mutation, # Probability of subtree mutation\n",
    "                                p_hoist_mutation=p_hoist_mutation, # Small probability of hoist mutation\n",
    "                                p_point_mutation=p_point_mutation, # Small probability of point mutation\n",
    "                                generations=1,\n",
    "                                random_state=random_state,\n",
    "                                feature_names=var_names,\n",
    "                                warm_start=var_names,\n",
    "                                metric=fitness\n",
    "    )\n",
    "    \n",
    "    for i in range(0, max_gen+1):\n",
    "        # CODE HERE\n",
    "    \n",
    "    orig = eq_df[eq_df.Filename == name]['Formula'].tolist()\n",
    "    \n",
    "    best_fit = loss_history[-1]\n",
    "    loss_histories[name] = loss_history\n",
    "    results.loc[len(results)] = [name, best_fit, orig[0], sr._program]\n",
    "    clear_output()\n",
    "    print(f'{cnt} {name} best_fit: {best_fit}')\n",
    "\n",
    "clear_output()\n",
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot the history for the validation metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Useful way to visualize a given formula\n",
    "dot_data=results.loc[3,\"equation\"].export_graphviz()\n",
    "graphviz.Source(dot_data)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
